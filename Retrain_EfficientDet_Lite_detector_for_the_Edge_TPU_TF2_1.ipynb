{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vvAObmTqglq"
   },
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qhl8lqVamEty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q tflite-model-maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.9/site-packages (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XtxiUeZEiXpt"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "dlopen(/opt/anaconda3/lib/python3.9/site-packages/tensorflow_lite_support/python/task/audio/pybinds/_pywrap_audio_classifier.so, 0x0002): Library not loaded: /usr/local/opt/libusb/lib/libusb-1.0.0.dylib\n  Referenced from: /opt/anaconda3/lib/python3.9/site-packages/tensorflow_lite_support/python/task/audio/pybinds/_pywrap_audio_classifier.so\n  Reason: tried: '/usr/local/opt/libusb/lib/libusb-1.0.0.dylib' (no such file), '/usr/local/lib/libusb-1.0.0.dylib' (no such file), '/usr/lib/libusb-1.0.0.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb#ch0000024?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb#ch0000024?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ExportFormat\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb#ch0000024?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m model_spec\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/raphaeldiaz/Desktop/Projet_IA_Emb/Projet_IA_Emb/Retrain_EfficientDet_Lite_detector_for_the_Edge_TPU_TF2_1.ipynb#ch0000024?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tflite_model_maker/__init__.py:44\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"Public APIs for TFLite Model Maker, a transfer learning library to train custom TFLite models.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mYou can install the package with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mhttps://www.tensorflow.org/lite/guide/model_maker.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_model_maker\u001b[39;00m \u001b[39mimport\u001b[39;00m image_classifier\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tflite_model_maker/audio_classifier/__init__.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# pylint: disable=g-bad-import-order,redefined-builtin\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"APIs to train an audio classification model.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mTutorial:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mhttps://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/demo/audio_classification_demo.py\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_dataloader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m AudioClassifier\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio_classifier\u001b[39;00m \u001b[39mimport\u001b[39;00m create\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/data_util/audio_dataloader.py:27\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_util\u001b[39;00m \u001b[39mimport\u001b[39;00m dataloader\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     29\u001b[0m error_import_librosa \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39minspect\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_spec\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m image_spec\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_spec\u001b[39;00m \u001b[39mimport\u001b[39;00m object_detector_spec\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec/audio_spec.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi_util\u001b[39;00m \u001b[39mimport\u001b[39;00m mm_export\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m model_util\n\u001b[1;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/model_util.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_examples\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlite\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_maker\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m compat\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m converter \u001b[39mas\u001b[39;00m tfjs_converter\n\u001b[0;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata \u001b[39mas\u001b[39;00m _metadata\n\u001b[1;32m     31\u001b[0m DEFAULT_SCALE, DEFAULT_ZERO_POINT \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     32\u001b[0m ESTIMITED_STEPS_PER_EPOCH \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tflite_support/__init__.py:53\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata_writers\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m platform\u001b[39m.\u001b[39msystem() \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWindows\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     52\u001b[0m   \u001b[39m# Task Library is not supported on Windows yet.\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m   \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m \u001b[39mimport\u001b[39;00m task\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tflite_support/task/__init__.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"The TensorFlow Lite Task Library.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mTensorFlow Lite Task Library contains a set of powerful and easy-to-use\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mhttps://tensorflow.org/lite/inference_with_metadata/task_library/overview).\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m audio\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m processor\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tflite_support/task/audio/__init__.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"TensorFlow Lite Task Library Audio APIs.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[39mThis module provides interface to run TensorFlow Lite audio models.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_classifier\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_embedder\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m audio_record\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/tensorflow_lite_support/python/task/audio/audio_classifier.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_audio\n\u001b[1;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpybinds\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_audio_buffer\n\u001b[0;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpybinds\u001b[39;00m \u001b[39mimport\u001b[39;00m _pywrap_audio_classifier\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m base_options \u001b[39mas\u001b[39;00m base_options_module\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_lite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprocessor\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m classification_options_pb2\n",
      "\u001b[0;31mImportError\u001b[0m: dlopen(/opt/anaconda3/lib/python3.9/site-packages/tensorflow_lite_support/python/task/audio/pybinds/_pywrap_audio_classifier.so, 0x0002): Library not loaded: /usr/local/opt/libusb/lib/libusb-1.0.0.dylib\n  Referenced from: /opt/anaconda3/lib/python3.9/site-packages/tensorflow_lite_support/python/task/audio/pybinds/_pywrap_audio_classifier.so\n  Reason: tried: '/usr/local/opt/libusb/lib/libusb-1.0.0.dylib' (no such file), '/usr/local/lib/libusb-1.0.0.dylib' (no such file), '/usr/lib/libusb-1.0.0.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import object_detector\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "mz_suhWiqc7A"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'Pedestrian', 2: 'People', 3: 'Bicycle', 4: 'Car', 5: 'Van', 6: 'Truck', 7: 'Tricycle', 8: 'Awning-tricycle', 9: 'Bus', 10: 'Motor', 11: 'Others', 12: 'None'}\n"
     ]
    }
   ],
   "source": [
    "# Your labels map as a dictionary (zero is reserved):\n",
    "label_map = {\n",
    "\n",
    "     1 : \"Pedestrian\",\n",
    "     2 : \"People\",\n",
    "     3 : \"Bicycle\",\n",
    "     4 : \"Car\",\n",
    "     5 : \"Van\",\n",
    "     6 : \"Truck\",\n",
    "     7 : \"Tricycle\",\n",
    "     8 : \"Awning-tricycle\",\n",
    "     9 : \"Bus\",\n",
    "     10 : \"Motor\",\n",
    "     11 : \"Others\",\n",
    "     12 : \"None\"\n",
    "}\n",
    "#file = open(\"Classeur1.txt\",\"r\")\n",
    "#lignes = file.readlines()\n",
    "#file.close()\n",
    "\n",
    "#for ligne in lignes:\n",
    "  #  element = ligne.split(\";\")\n",
    "   # cle = int(element[0])\n",
    "    #print(cle)\n",
    "    #data = element[1]\n",
    "    #print(data)\n",
    "    #label_map[cle] = data\n",
    "print (label_map)\n",
    "\n",
    "# If it's NOT split yet, specify the path to all images and annotations\n",
    "images_in = 'C:\\\\Users\\\\diazy\\\\Desktop\\\\Reentrainement\\\\VisDrone2019-DET-train\\\\images_new'\n",
    "annotations_in = 'C:\\\\Users\\\\diazy\\\\Desktop\\\\Reentrainement\\\\VisDrone2019-DET-train\\\\annotations_new'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": "form",
    "id": "C35meprE8xzf"
   },
   "outputs": [],
   "source": [
    "#@markdown Be sure you run this cell. It's hiding the `split_dataset()` function used in the next code block.\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n",
    "  \"\"\"Splits a directory of sorted images/annotations into training, validation, and test sets.\n",
    "\n",
    "  Args:\n",
    "    images_path: Path to the directory with your images (JPGs).\n",
    "    annotations_path: Path to a directory with your VOC XML annotation files,\n",
    "      with filenames corresponding to image filenames. This may be the same path\n",
    "      used for images_path.\n",
    "    val_split: Fraction of data to reserve for validation (float between 0 and 1).\n",
    "    test_split: Fraction of data to reserve for test (float between 0 and 1).\n",
    "  Returns:\n",
    "    The paths for the split images/annotations (train_dir, val_dir, test_dir)\n",
    "  \"\"\"\n",
    "  _, dirs, _ = next(os.walk(images_path))\n",
    "\n",
    "  train_dir = os.path.join(out_path, 'train')\n",
    "  val_dir = os.path.join(out_path, 'validation')\n",
    "  test_dir = os.path.join(out_path, 'test')\n",
    "\n",
    "  IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images_new')\n",
    "  IMAGES_VAL_DIR = os.path.join(val_dir, 'images_new')\n",
    "  IMAGES_TEST_DIR = os.path.join(test_dir, 'images_new')\n",
    "  os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
    "  os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
    "  os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n",
    "\n",
    "  ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations_new')\n",
    "  ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations_new')\n",
    "  ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations_new')\n",
    "  os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n",
    "  os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n",
    "  os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n",
    "\n",
    "  # Get all filenames for this dir, filtered by filetype\n",
    "  filenames = os.listdir(os.path.join(images_path))\n",
    "  filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n",
    "  # Shuffle the files, deterministically\n",
    "  filenames.sort()\n",
    "  random.seed(42)\n",
    "  random.shuffle(filenames)\n",
    "  # Get exact number of images for validation and test; the rest is for training\n",
    "  val_count = int(len(filenames) * val_split)\n",
    "  test_count = int(len(filenames) * test_split)\n",
    "  for i, file in enumerate(filenames):\n",
    "    source_dir, filename = os.path.split(file)\n",
    "    annot_file = os.path.join(annotations_path, filename.replace(\"jpg\", \"xml\"))\n",
    "    if i < val_count:\n",
    "      shutil.copy(file, IMAGES_VAL_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_VAL_DIR)\n",
    "    elif i < val_count + test_count:\n",
    "      shutil.copy(file, IMAGES_TEST_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_TEST_DIR)\n",
    "    else:\n",
    "      shutil.copy(file, IMAGES_TRAIN_DIR)\n",
    "      shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n",
    "  return (train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KWROlVNA54xZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train count: 3464\n",
      "validation count: 1154\n",
      "test count: 1154\n"
     ]
    }
   ],
   "source": [
    "# We need to instantiate a separate DataLoader for each split dataset\n",
    "train_dir, val_dir, test_dir = split_dataset(images_in, annotations_in,\n",
    "                                                 val_split=0.2, test_split=0.2,\n",
    "                                                 out_path='split-dataset')\n",
    "train_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(train_dir, 'images_new'),\n",
    "    os.path.join(train_dir, 'annotations_new'), label_map=label_map)\n",
    "validation_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(val_dir, 'images_new'),\n",
    "    os.path.join(val_dir, 'annotations_new'), label_map=label_map)\n",
    "test_data = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(test_dir, 'images_new'),\n",
    "    os.path.join(test_dir, 'annotations_new'), label_map=label_map)\n",
    "    \n",
    "print(f'train count: {len(train_data)}')\n",
    "print(f'validation count: {len(validation_data)}')\n",
    "print(f'test count: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SM9gePHw9Jv1"
   },
   "outputs": [],
   "source": [
    "#spec = object_detector.EfficientDetLite0Spec(hparams{'max_instances_per_image': MAXOBJECTCOUNT})\n",
    "spec = object_detector.EfficientDetLite3Spec(\n",
    "  model_name='efficientdet-lite3', \n",
    "  uri='https://tfhub.dev/tensorflow/efficientdet/lite3/feature-vector/1', \n",
    "  hparams={'max_instances_per_image': 8000},\n",
    "  strategy='gpus',\n",
    "  model_dir = 'C:\\\\Users\\\\diazy\\\\Desktop\\\\Reentrainement\\\\new' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kwlYdTcg63xy"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\diazy\\AppData\\Local\\Temp\\tfhub_modules\\c683d6e0617380b32ffc04f38c79f57c18271787\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16708\\2391450931.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = object_detector.create(train_data=train_data, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                \u001b[0mmodel_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                train_whole_model=False)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(cls, train_data, model_spec, validation_data, epochs, batch_size, train_whole_model, do_train)\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m       \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Retraining the models...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m       \u001b[0mobject_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0mobject_detector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_data, validation_data, epochs, batch_size)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mds_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m       train_ds, steps_per_epoch, _ = self._get_dataset_and_steps(\n\u001b[0;32m    120\u001b[0m           train_data, batch_size, is_training=True)\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\object_detector.py\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\object_detector_spec.py\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;34m\"\"\"Creates the EfficientDet model.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m     return train_lib.EfficientDetNetTrainHub(\n\u001b[0m\u001b[0;32m    239\u001b[0m         config=self.config, hub_module_url=self.uri)\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\third_party\\efficientdet\\keras\\train_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, hub_module_url, name)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhub_module_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub_module_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhub_module_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m     \u001b[1;31m# class/box output prediction network.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_training_argument\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_has_training_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_is_hub_module_v1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_hub\\keras_layer.py\u001b[0m in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Expected before TF2.4.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[0mset_load_options\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodule_v2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_load_options\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m   \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 949\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m   \"\"\"\n\u001b[1;32m---> 57\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   debug_info_path = file_io.join(\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\diazy\\AppData\\Local\\Temp\\tfhub_modules\\c683d6e0617380b32ffc04f38c79f57c18271787\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = object_detector.create(train_data=train_data, \n",
    "                               model_spec=spec,  \n",
    "                               epochs=10, \n",
    "                               batch_size=24,\n",
    "                               train_whole_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = object_detector.create(train_data=train_data, \n",
    "                              # model_spec=spec, \n",
    "                               #validation_data=validation_data, \n",
    "                               #epochs=10, \n",
    "                               #batch_size=120,\n",
    "                               \n",
    "                               #train_whole_model=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8xmnl6Yy7ARn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 231s 9s/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AP': 1.0411734e-06,\n",
       " 'AP50': 4.4543203e-06,\n",
       " 'AP75': 2.8513392e-07,\n",
       " 'APs': 2.7567327e-07,\n",
       " 'APm': 7.361273e-06,\n",
       " 'APl': 3.1858395e-05,\n",
       " 'ARmax1': 5.413599e-06,\n",
       " 'ARmax10': 5.864732e-05,\n",
       " 'ARmax100': 0.00037895193,\n",
       " 'ARs': 0.00012726751,\n",
       " 'ARm': 0.00048808317,\n",
       " 'ARl': 0.0015245478,\n",
       " 'AP_/Pedestrian': 0.0,\n",
       " 'AP_/People': 0.0,\n",
       " 'AP_/Bicycle': 0.0,\n",
       " 'AP_/Car': 1.249408e-05,\n",
       " 'AP_/Van': 0.0,\n",
       " 'AP_/Truck': 0.0,\n",
       " 'AP_/Tricycle': 0.0,\n",
       " 'AP_/Awning-tricycle': 0.0,\n",
       " 'AP_/Bus': 0.0,\n",
       " 'AP_/Motor': 0.0,\n",
       " 'AP_/Others': 0.0,\n",
       " 'AP_/None': 0.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "model.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "2Cu9cxX5Qu-e"
   },
   "outputs": [],
   "source": [
    "TFLITE_FILENAME = 'efficientdet-lite-new1.tflite'\n",
    "LABELS_FILENAME = 'labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "rKd6qk7TbxYO"
   },
   "outputs": [],
   "source": [
    "model.export(export_dir='C:\\\\Users\\\\diazy\\\\Desktop\\\\Reentrainement', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
    "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ObjectDetector' object has no attribute 'analyse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23492\\2214461192.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalyse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'ObjectDetector' object has no attribute 'analyse'"
     ]
    }
   ],
   "source": [
    "model.analyse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RS3Ell_lqH4e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.evaluate_tflite(TFLITE_FILENAME, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path='C:\\\\Users\\\\diazy\\\\Desktop\\\\Reentrainement\\\\split-dataset'\n",
    "test_dir_small = os.path.join(out_path, 'test')\n",
    "test_data_small = object_detector.DataLoader.from_pascal_voc(\n",
    "    os.path.join(test_dir_small, 'images_small'),\n",
    "    os.path.join(test_dir_small, 'annotations_small'), label_map=label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate_tflite(TFLITE_FILENAME, test_data_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eag7jTOASGFW"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# If you're using a custom dataset, we take a random image from the test set:\n",
    "\n",
    "images_path = test_images_dir if dataset_is_split else os.path.join(test_dir, \"images_new\")\n",
    "filenames = os.listdir(os.path.join(images_path))\n",
    "random_index = random.randint(0,len(filenames)-1)\n",
    "INPUT_IMAGE = os.path.join(images_path, filenames[random_index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBecI78ZaxsO"
   },
   "source": [
    "To simplify our code, we'll use the [PyCoral API](https://coral.ai/docs/reference/py/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmgtGBqua1N3"
   },
   "outputs": [],
   "source": [
    "! python -m pip install --extra-index-url https://google-coral.github.io/py-repo/ pycoral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkXtipXKqXp4"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "\n",
    "#import tflite_runtime.interpreter as tflite \n",
    "from pycoral.adapters import common\n",
    "from pycoral.adapters import detect\n",
    "from pycoral.utils.dataset import read_label_file\n",
    "\n",
    "def draw_objects(draw, objs, scale_factor, labels):\n",
    "  \"\"\"Draws the bounding box and label for each object.\"\"\"\n",
    "  COLORS = np.random.randint(0, 255, size=(len(labels), 3), dtype=np.uint8)\n",
    "  for obj in objs:\n",
    "    bbox = obj.bbox\n",
    "    color = tuple(int(c) for c in COLORS[obj.id])\n",
    "    draw.rectangle([(bbox.xmin * scale_factor, bbox.ymin * scale_factor),\n",
    "                    (bbox.xmax * scale_factor, bbox.ymax * scale_factor)],\n",
    "                   outline=color, width=3)\n",
    "    font = ImageFont.truetype(\"LiberationSans-Regular.ttf\", size=15)\n",
    "    draw.text((bbox.xmin * scale_factor + 4, bbox.ymin * scale_factor + 4),\n",
    "              '%s\\n%.2f' % (labels.get(obj.id, obj.id), obj.score),\n",
    "              fill=color, font=font)\n",
    "\n",
    "# Load the TF Lite model\n",
    "labels = read_label_file(LABELS_FILENAME)\n",
    "interpreter = interpreter.Interpreter(TFLITE_FILENAME)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Resize the image for input\n",
    "image = Image.open(INPUT_IMAGE)\n",
    "_, scale = common.set_resized_input(\n",
    "    interpreter, image.size, lambda size: image.resize(size, Image.ANTIALIAS))\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "objs = detect.get_objects(interpreter, score_threshold=0.4, image_scale=scale)\n",
    "\n",
    "# Resize again to a reasonable size for display\n",
    "display_width = 500\n",
    "scale_factor = display_width / image.width\n",
    "height_ratio = image.height / image.width\n",
    "image = image.resize((display_width, int(display_width * height_ratio)))\n",
    "draw_objects(ImageDraw.Draw(image), objs, scale_factor, labels)\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oy3QIn_YqaRP"
   },
   "outputs": [],
   "source": [
    "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "\n",
    "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "\n",
    "! sudo apt-get update\n",
    "\n",
    "! sudo apt-get install edgetpu-compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZdonJGCqieU"
   },
   "outputs": [],
   "source": [
    "NUMBER_OF_TPUS =  1\n",
    "\n",
    "!edgetpu_compiler $TFLITE_FILENAME -d --num_segments=$NUMBER_OF_TPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M43URVgg0ZcB"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(TFLITE_FILENAME)\n",
    "files.download(TFLITE_FILENAME.replace('.tflite', '_edgetpu.tflite'))\n",
    "files.download(LABELS_FILENAME)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "license"
   ],
   "name": "Retrain EfficientDet-Lite detector for the Edge TPU (TF2)",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
